<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Phenomenal Eevee</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html">
 <span class="menu-text">TEAM NAME</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./proposal.html">
 <span class="menu-text">Proposal</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./eda.html">
 <span class="menu-text">Exploratory data analysis</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./pre-registration.html">
 <span class="menu-text">Pre-registered analyses</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./presentation.html">
 <span class="menu-text">Presentation</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="./report.html" aria-current="page">
 <span class="menu-text">Report</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./appendicies.qmd">
 <span class="menu-text">Appendicies</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./about.html">
 <span class="menu-text">About</span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#data-description" id="toc-data-description" class="nav-link" data-scroll-target="#data-description">Data description</a></li>
  <li><a href="#data-analysis" id="toc-data-analysis" class="nav-link" data-scroll-target="#data-analysis">Data analysis</a></li>
  <li><a href="#evaluation-of-significance" id="toc-evaluation-of-significance" class="nav-link" data-scroll-target="#evaluation-of-significance">Evaluation of significance</a></li>
  <li><a href="#interpretation-and-conclusions" id="toc-interpretation-and-conclusions" class="nav-link" data-scroll-target="#interpretation-and-conclusions">Interpretation and conclusions</a></li>
  <li><a href="#limitations" id="toc-limitations" class="nav-link" data-scroll-target="#limitations">Limitations</a></li>
  <li><a href="#acknowledgments" id="toc-acknowledgments" class="nav-link" data-scroll-target="#acknowledgments">Acknowledgments</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Phenomenal Eevee</h1>
<p class="subtitle lead">Report</p>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>Streaming platforms have taken the world by storm due to their convenience and ability to house innumerable popular television shows and movies. As these mediums continue to grow in popularity, discourse about them is also developing and is often centered around one primary question: Which platform is best? Throughout our data analysis, our team seeks to answer this aforementioned question to the best of our ability, taking an in-depth look at four mainstream services —- Netflix, Amazon Prime Video, Hulu, and Disney+ —- and the programs that have been present on the site throughout roughly the past two decades. Specifically, we use rankings developed by Rotten Tomatoes and hypothesis testing to approach two research questions:</p>
<p><strong>RQ1: “Is the quality of exclusive shows different from non-exclusive shows across platforms?”</strong></p>
<p><strong>RQ2: “Are exclusive shows’ ratings different between the four platforms (Netflix, Hulu, Disney+, and Prime Video)?”</strong></p>
<p>Our <code>tv_shows</code> dataset was taken from Kaggle and originally contained the following variables: <code>ID</code> , <code>Title</code>, <code>Year</code>, <code>Age</code>, <code>IMDb</code>, <code>Rotten Tomatoes</code>, <code>Netflix</code>, <code>Hulu</code>, <code>Prime Video</code>, <code>Disney+</code>, and <code>Type.</code>The original dataset contains 12 columns and 5368 observations. Each of the variables above were used to describe an observation of a television show featured on the four platforms we’re analyzing. In our data cleaning process, we made some of the variables easier to understand; in the <code>Netflix</code>, <code>Hulu</code>, <code>Prime Video</code>, <code>Disney+</code> variables, we changed 0 or 1 binary results to “Yes” or “No” depending on whether a certain show is present on each platform. Additionally, we mutated the data to add four columns: <code>exclusive_netflix</code>, <code>exclusive_prime_video</code>, <code>exclusive_disney_plus,</code> and <code>exclusive_hulu</code>, which contains “TRUE” or “FALSE” data to indicate whether an observation is exclusively seen on the platform at hand. Finally, we removed the ‘%’ in the <code>Rotten Tomatoes</code> score and converted the values to integers to make them easier to use in our analysis.</p>
<p>After conducting two hypothesis tests and interpreting the results (including the p-value, point-estimate, and confidence interval values), we were able to determine a few conclusions with respect to the research questions above. Regarding the first hypothesis, we were able to reject the null hypothesis and were in favor of the alternative hypothesis. This means that the first hypothesis test provides convincing evidence that the average quality of exclusive shows (measured by Rotten Tomatoes scores) is greater than the average quality of non-exclusive shows (measured by Rotten Tomatoes scores) across all platforms. In terms of the second research question, our findings were in favor of the alternate hypothesis: there is some sort of difference in ratings between the exclusive shows on each of the four platforms.</p>
</section>
<section id="data-description" class="level1">
<h1>Data description</h1>
<p>The observations (rows) of the <code>tvshows</code> dataset represent each individual TV show that is readily watched and broadcasted on at least one of the four top ranking broadcasting platforms (we are focusing on Hulu, Disney+, Prime Video and Netflix). The attributes (columns) of the <code>tvshows</code> data set categorizes each individual TV show based on the streaming platform it’s being broadcasted on and reveals additional information. This includes revealing the year the TV show was produced, target age group of audience, and the rating of the show (by the Rotten Tomatoes metric).</p>
<p>This data set was created by the curator after being inspired by personal experiences of wanting to know more about which streaming platform(s) a particular TV show can be found on. Furthermore, the curator wished to explore potential relationships between target age group of audience, year of production, and the streaming platform the show can be found on. The creation of the <code>tvshows</code> dataset was not funded by anyone and was curated solely with the desire to learn more about tv shows readily broadcasted on top streaming platforms. Specifically, the curator likely looked at TV shows broadcasted on each streaming platform to determine which Rotten Tomatoes ratings to include within the dataset and determine which year of production data as well as target age of audience should be included.</p>
<p>In regards to the pre-processing of the data, the Rotten Tomatoes score itself needed to undergo specific calculations before the curator is able to scrape the Rotten Tomatoes score for the corresponding TV shows. To summarize, the Rotten Tomatoes score is calculated only when the show receives at least 5 reviews. Then, the critic’s rating of “Fresh” (positive) or “Rotten” bad is collected and the Rotten Tomatoes percentage is calculated by dividing the number of “Fresh” scores by the total number of “Fresh” and “Rotten” scores times 100. In addition, the curator then used a binary system (0 for “no” and 1 for “yes”) to classify which streaming platform(s) each TV show can be found on.</p>
<p>The curator did not involve any other people during the data collection and likely collected the data from official sites that reported the taken corresponding data values. At the same time, the Rotten Tomatoes data values inherently involve people as the score is reliant on people’s opinions and rating of the show. From this perspective, the people are likely aware of this data collection as they are displaying their ratings of the tv shows in a public domain. They likely expected their data to be used to contribute to the overall rating of the TV show and used to inform others on whether they should watch the respective TV show.</p>
</section>
<section id="data-analysis" class="level1">
<h1>Data analysis</h1>
<div class="cell">
<div class="cell-output cell-output-stderr">
<pre><code>── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
✔ dplyr     1.1.2     ✔ readr     2.1.4
✔ forcats   1.0.0     ✔ stringr   1.5.0
✔ ggplot2   3.4.2     ✔ tibble    3.2.1
✔ lubridate 1.9.2     ✔ tidyr     1.3.0
✔ purrr     1.0.1     
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()
ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors
── Attaching packages ────────────────────────────────────── tidymodels 1.0.0 ──

✔ broom        1.0.4     ✔ rsample      1.1.1
✔ dials        1.1.0     ✔ tune         1.1.1
✔ infer        1.0.4     ✔ workflows    1.1.2
✔ modeldata    1.0.1     ✔ workflowsets 1.0.0
✔ parsnip      1.0.3     ✔ yardstick    1.2.0
✔ recipes      1.0.6     

── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──
✖ scales::discard() masks purrr::discard()
✖ dplyr::filter()   masks stats::filter()
✖ recipes::fixed()  masks stringr::fixed()
✖ dplyr::lag()      masks stats::lag()
✖ yardstick::spec() masks readr::spec()
✖ recipes::step()   masks stats::step()
• Search for functions across packages at https://www.tidymodels.org/find/

Loading required package: viridisLite


Attaching package: 'viridis'


The following object is masked from 'package:scales':

    viridis_pal


New names:
Rows: 5368 Columns: 12
── Column specification ────────────────────────────────────────────────────────
Delimiter: ","
chr (4): Title, Age, IMDb, Rotten Tomatoes
dbl (8): ...1, ID, Year, Netflix, Hulu, Prime Video, Disney+, Type

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 5,368 × 16
    ...1    ID Title            Year Age   IMDb  `Rotten Tomatoes` Netflix Hulu 
   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;           &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;             &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;
 1     0     1 Breaking Bad     2008 18+   9.4/…               100 Yes     No   
 2     1     2 Stranger Things  2016 16+   8.7/…                96 Yes     No   
 3     2     3 Attack on Titan  2013 18+   9.0/…                95 Yes     Yes  
 4     3     4 Better Call Sa…  2015 18+   8.8/…                94 Yes     No   
 5     4     5 Dark             2017 16+   8.8/…                93 Yes     No   
 6     5     6 Avatar: The La…  2005 7+    9.3/…                93 Yes     No   
 7     6     7 Peaky Blinders   2013 18+   8.8/…                93 Yes     No   
 8     7     8 The Walking De…  2010 18+   8.2/…                93 Yes     No   
 9     8     9 Black Mirror     2011 18+   8.8/…                92 Yes     No   
10     9    10 The Queen's Ga…  2020 18+   8.6/…                92 Yes     No   
# ℹ 5,358 more rows
# ℹ 7 more variables: `Prime Video` &lt;chr&gt;, `Disney+` &lt;chr&gt;, Type &lt;dbl&gt;,
#   exclusive_netflix &lt;lgl&gt;, exclusive_hulu &lt;lgl&gt;, exclusive_prime_video &lt;lgl&gt;,
#   exclusive_disney_plus &lt;lgl&gt;</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1761</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1334</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1597</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 306</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 5,368 × 16
    ...1    ID Title            Year Age   IMDb  `Rotten Tomatoes` Netflix Hulu 
   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;           &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;             &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;
 1     0     1 Breaking Bad     2008 18+   9.4/…               100 Yes     No   
 2     1     2 Stranger Things  2016 16+   8.7/…                96 Yes     No   
 3     2     3 Attack on Titan  2013 18+   9.0/…                95 Yes     Yes  
 4     3     4 Better Call Sa…  2015 18+   8.8/…                94 Yes     No   
 5     4     5 Dark             2017 16+   8.8/…                93 Yes     No   
 6     5     6 Avatar: The La…  2005 7+    9.3/…                93 Yes     No   
 7     6     7 Peaky Blinders   2013 18+   8.8/…                93 Yes     No   
 8     7     8 The Walking De…  2010 18+   8.2/…                93 Yes     No   
 9     8     9 Black Mirror     2011 18+   8.8/…                92 Yes     No   
10     9    10 The Queen's Ga…  2020 18+   8.6/…                92 Yes     No   
# ℹ 5,358 more rows
# ℹ 7 more variables: `Prime Video` &lt;chr&gt;, `Disney+` &lt;chr&gt;, Type &lt;dbl&gt;,
#   exclusive_netflix &lt;lgl&gt;, exclusive_hulu &lt;lgl&gt;, exclusive_prime_video &lt;lgl&gt;,
#   exclusive_disney_plus &lt;lgl&gt;</code></pre>
</div>
</div>
<div class="cell">
<div class="cell-output cell-output-stderr">
<pre><code>`summarise()` has grouped output by 'decile'. You can override using the
`.groups` argument.</code></pre>
</div>
<div class="cell-output-display">
<p><img src="report_files/figure-html/explaratory-data-analysis-1.png" class="img-fluid" width="672"></p>
</div>
<div class="cell-output-display">
<p><img src="report_files/figure-html/explaratory-data-analysis-2.png" class="img-fluid" width="672"></p>
</div>
<div class="cell-output-display">
<p><img src="report_files/figure-html/explaratory-data-analysis-3.png" class="img-fluid" width="672"></p>
</div>
</div>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 5 × 5
  term             estimate std.error statistic   p.value
  &lt;chr&gt;               &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
1 (Intercept)       35.5        0.937   37.8    8.27e-278
2 NetflixYes        17.0        0.929   18.3    1.01e- 72
3 HuluYes           15.8        0.891   17.7    2.07e- 68
4 `Prime Video`Yes  -0.0767     0.920   -0.0834 9.34e-  1
5 `Disney+`Yes      11.9        1.26     9.43   5.70e- 21</code></pre>
</div>
</div>
<p><strong>Fraction of shows that are in a given rating interval for each platform:</strong></p>
<p>The graph titled <em>Fraction of shows that are in a given rating interval for each platform</em> is a normalized frequency bar chart where every bar has the same height so that each bar represents the proportion of each rating (in our case: rotten tomatoes score) interval for a given platform. This allows us to normalize the number of shows in each platform and reduce the bias of different platforms having different number of shows. In this graph, the y-axis represents the fraction of shows (compared to the overall number of shows) rather than the actual number of shows on each platform. This allows us to compare the rotten tomato scores of shows of each platform as well as across all the platforms. The x-axis represents the rotten tomato score intervals (decided) that we chose to categorize and group the shows based on.</p>
<p>Based on the graph we can deduce that Hulu and Netflix have equally large proportion of shows ranked between 91 and 100 on rotten tomatoes. Prime Video has the third largest proportion of shows in that interval of rotten tomatoes scores, followed by the last platform, which is Disney+. The same tendency is consistent for rotten tomatoes score intervals 51-60, 61-70, 71-80, and 81-90 rotten tomatoes score intervals. The proportion of shows that have the lowest rotten tomatoes score is the largest for Prime Video. Shows ranked within the interval of 1-10 are mostly streamed on Prime Video. In general, it seems like Netflix and Hulu have the largest proportion of shows that are ranked relatively high on rotten tomatoes, meanwhile Prime Video has the largest proportion of shows that are ranked the lowest on rotten tomatoes.</p>
<p><strong>Ratings of Streamed Shows by Platform:</strong></p>
<p>This graph shows boxplots that represent the distribution of rotten tomatoes scores of shows on each platform. The heights of the boxplots represent the diversity of data points (in this case rotten tomatoes scores) on each platform. The rotten tomatoes scores of shows in Disney+ are the most consistent across all the shows and are similar to each other with the median rotten tomatoes score being 50 (indicated by the horizontal line). The same is true for scores of shows streaming on Netflix. On the other hand, because the boxplot for shows streaming on Prime Video is well spread out across the y-axis, meaning its IQR is large, the scores for the shows streaming on Prime Video have varying range and are not consistent or similar across all the shows on the platform. This also means that even though there is a mean value of around 40, we cannot make meaningful conclusions about Prime Video show scores that would be relevant and valid for all the shows across the platform. This said, comparatively it seems that Hulu has the highest median score for its shows.</p>
<p><strong>Mean Ratings of Streamed Shows by Platform</strong></p>
<p>This graph shows the mean rotten tomatoes score of shows per platform. Netflix and Hulu seem to have almost the same mean rotten tomatoes score with Netflix slightly dominating. On the third place with rotten tomatoes score is Disney+, which is followed by Prime Vide that has the lowest mean score for shows streaming on it.</p>
<p>Overall, these exploratory data visualizations show that there is a difference between rotten tomatoes scores for shows on different platforms. Moving forward we explore the possible factors (exclusivity of the shows to each platform) that might affect these differences.</p>
</section>
<section id="evaluation-of-significance" class="level1">
<h1>Evaluation of significance</h1>
<section id="first-analysis-hypothesis-test" class="level4">
<h4 class="anchored" data-anchor-id="first-analysis-hypothesis-test"><strong><em>First Analysis: Hypothesis Test</em></strong></h4>
<p><strong>Research Question:</strong> Is the quality of exclusive shows different from non-exclusive shows across all streaming platforms?</p>
<p><strong>Null Hypothesis</strong>: The average Rotten Tomatoes score of exclusive shows is less than the average Rotten Tomatoes score of non-exclusive shows across all four platforms.</p>
<p><span class="math display">\[
H_0: \mu_{exclusive} &lt; \mu_{non-exclusive}
\]</span></p>
<p>Alternative Hypothesis: The average Rotten Tomatoes score of exclusive shows is greater than the average Rotten Tomatoes score of non-exclusive shows across all four platforms.</p>
<p><span class="math display">\[
H_0: \mu_{exclusive} &gt; \mu_{non-exclusive}
\]</span></p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Response: rotten_tomatoes (numeric)
Explanatory: exclusivity (factor)
# A tibble: 1 × 1
   stat
  &lt;dbl&gt;
1 -1.14</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 1
  p_value
    &lt;dbl&gt;
1   0.001</code></pre>
</div>
<div class="cell-output-display">
<p><img src="report_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid" width="672"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 2
  lower_ci upper_ci
     &lt;dbl&gt;    &lt;dbl&gt;
1    -1.76   -0.540</code></pre>
</div>
</div>
<p><strong><em>Second Analysis: Hypothesis Test</em></strong></p>
<p><strong>Research Question:</strong> Are exclusive shows’ ratings different between the four platforms (Netflix, Hulu, Disney+, and Prime Video)?</p>
<p><strong>Null Hypothesis</strong>: There is no difference in quality of the exclusive shows between the four platforms.</p>
<p><span class="math display">\[
H_0: μ1 = μ2 = μ3 = μ4
\]</span></p>
<p><strong>Alternate Hypothesis:</strong> There is a difference in quality of the exclusive shows between the four platforms.</p>
<p><span class="math display">\[
H_A: μ1 ≠ μ2 ≠ μ3 ≠ μ4
\]</span></p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 4 × 2
  term                       estimate
  &lt;chr&gt;                         &lt;dbl&gt;
1 intercept                     52.7 
2 showsexclusive_disney_plus    -4.60
3 showsexclusive_hulu           -1.56
4 showsexclusive_prime_video   -17.9 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: Please be cautious in reporting a p-value of 0. This result is an
approximation based on the number of `reps` chosen in the `generate()` step. See
`?get_p_value()` for more information.

Warning: Please be cautious in reporting a p-value of 0. This result is an
approximation based on the number of `reps` chosen in the `generate()` step. See
`?get_p_value()` for more information.

Warning: Please be cautious in reporting a p-value of 0. This result is an
approximation based on the number of `reps` chosen in the `generate()` step. See
`?get_p_value()` for more information.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 4 × 2
  term                       p_value
  &lt;chr&gt;                        &lt;dbl&gt;
1 intercept                     0   
2 showsexclusive_disney_plus    0   
3 showsexclusive_hulu           0.02
4 showsexclusive_prime_video    0   </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 4 × 3
  term                       lower_ci upper_ci
  &lt;chr&gt;                         &lt;dbl&gt;    &lt;dbl&gt;
1 intercept                     52.0    53.5  
2 showsexclusive_disney_plus    -6.41   -2.77 
3 showsexclusive_hulu           -2.81   -0.310
4 showsexclusive_prime_video   -19.0   -16.6  </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: F usually corresponds to right-tailed tests. Proceed with caution.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: F usually corresponds to right-tailed tests. Proceed with caution.

Warning: F usually corresponds to right-tailed tests. Proceed with caution.

Warning: F usually corresponds to right-tailed tests. Proceed with caution.</code></pre>
</div>
<div class="cell-output-display">
<p><img src="report_files/figure-html/multivariate-hypothesis-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</section>
</section>
<section id="interpretation-and-conclusions" class="level1">
<h1>Interpretation and conclusions</h1>
<p><strong>Hypothesis #1: Point-Estimate</strong></p>
<p>The point estimate -1.141822 represents, on average, the estimated difference of mean Rotten Tomatoes ratings between exclusive shows (to only one platform) and non exclusive shows across all four platforms.</p>
<p><strong>Hypothesis #1: Confidence Interval</strong></p>
<p>The 95% confidence interval [-1.78, -0.500] represents that we can be 95% confident that the difference in average Rotten Tomato rating between exclusive and non-exclusive shows across all platforms observed in the real population falls into the observed range of the confidence interval.</p>
<p>Additionally, since the bootstrapped confidence interval [-1.78, -0.500] does not include 0 in its interval, we can confidently rule out the possibility that exclusive shows across all platforms do not have a significant influence on Rotten Tomatoes ratings. In other words, since the confidence interval does not include 0, this suggests that the difference in average Rotten Tomato ratings between exclusive and non-exclusive shows is statistically significant and that exclusive shows has a significant influence on average Rotten Tomatoes ratings.</p>
<p><strong>Hypothesis #1: P-Values</strong></p>
<p>The calculated p-value for the difference in mean Rotten Tomato ratings between exclusive and non-exclusive shows across all 4 platforms is approximately 0.001. Since this calculated p-value is smaller than the significance level indicated by <span class="math inline">\(\alpha\)</span> = 0.05, we are able to reject the null hypothesis (the average Rotten Tomatoes score of exclusive shows is less than the average Rotten Tomatoes score of non-exclusive shows across all four platforms.). In other words, there was convincing evidence that would favor the alternative hypothesis which indicates that the average Rotten Tomatoes score of exclusive shows is greater than the average Rotten Tomatoes score of non-exclusive shows across all four platforms.</p>
<p><strong>Hypothesis #1: Simulation-Based Null Distributions Visualization</strong></p>
<p>The visualization displays the null distribution and the p-value (shown by the red line). Specifically, the null distribution displayed represents the distribution of the difference of mean Rotten Tomatoes scores between exclusive and non-exclusive shows under the assumption that the null hypothesis is true. Based on the visualization, the p-value is found on the left of the null distribution. Since a one-tailed test was conducted, the critical region is found on the left side of the null distribution. This then indicates that the observed test statistic (the difference in mean Rotten Tomatoes scores) falls within the critical region. This means that the difference in mean Rotten Tomatoes scores is smaller than what would be expected under the null hypothesis. This also means the observed data is unlikely to have occurred by chance alone, assuming the null hypothesis is true. Thus, correspondingly, the p-value will be a very small value and would overall provide evidence in support of the alternative hypothesis: the difference in mean Rotten Tomato ratings between exclusive and non-exclusive shows across all platforms is statistically significant in the direction specified by the alternative hypothesis (the average Rotten Tomatoes score of exclusive shows is greater than the average Rotten Tomatoes score of non-exclusive shows across all four platforms).</p>
<p><strong>Hypothesis #2: Point Estimate</strong></p>
<p>The intercept 52.747303 represents, on average, the Rotten Tomatoes score for exclusive Netflix shows.</p>
<p>The estimated Rotten Tomatoes score for exclusive Disney plus shows, on average, will be 4.600244 less than the exclusive Netflix shows Rotten Tomatoes score. The estimated Rotten Tomatoes score for exclusive Hulu shows, on average, will be 1.556898 less than the exclusive Netflix shows Rotten Tomatoes score. The estimated Rotten Tomatoes score for exclusive Prime video shows, on average, will be 17.856883 less than the exclusive Netflix shows Rotten Tomatoes score.</p>
<p><strong>Hypothesis #2: Confidence Intervals</strong></p>
<p>The 95% confidence intervals for observing the estimated Rotten Tomatoes scores for shows exclusive to either Hulu, Disney+, or Prime Video are</p>
<ul>
<li><p>[-6.406644, -2.7691091] for <code>exclusive_disney_plus</code></p></li>
<li><p>[-2.813665, -0.3103026] for <code>exclusive_hulu</code></p></li>
<li><p>[-19.043264, -16.124430] for <code>exclusive_prime_video</code></p></li>
</ul>
<p>Since all the above confidence intervals include 0 within their interval, we cannot confidently rule out the possibility that shows exclusive to either Hulu, Disney+, or Prime Video do not have a significant influence on Rotten Tomatoes ratings; we cannot be confident that the estimated scores for these streaming platforms are statistically different from 0.</p>
<p>The 95% confidence interval [52.019703, 53.415572] for the intercept (which represents the exclusive_netflix column) shows that we can be confident that the estimated Rotten Tomato score for exclusive Netflix shows is within the given confidence interval range.</p>
<p><strong>Hypothesis #2: P-Values</strong></p>
<p>The intercept p-value is 0.001 which represents the p-value for exclusive Netflix shows. For exclusive shows on Prime Video and Disney Plus, we calculated a p-value of 0.001 whereas exclusive shows on Hulu had a p-value of 0.02. Since the p-values for exclusive shows on all 4 platforms are less than the significance level indicated by <span class="math inline">\(\alpha\)</span> = 0.05, we are able to reject the null hypothesis (there is no difference in quality of the exclusive shows between the four platforms). This means that there was convincing evidence that would favor the alternative hypothesis which indicates that there is a difference in quality of the exclusive shows between the four platforms (measured through Rotten Tomatoes scores).</p>
<p><strong>Hypothesis #2: Simulation-Based Null Distributions Visualization</strong></p>
<p>The visualizations of <code>exclusive_disney_plus,</code> <code>exclusive_prime_video</code>, <code>exclusive_hulu</code>, and the <code>intercept</code> display the null distribution in reference to the p-value (the red line). A null distribution that is far from the p-value (as seen in <code>exclusive_prime_video,</code> <code>exclusive_disney_plus,</code> and the <code>intercept</code>) indicates that the observed difference in ratings between the four platforms is larger than what would be expected under the null hypothesis. Hence, the p-value is small because the observed difference is unlikely to be due to chance. Additionally, we can also reasonably say that, in the case of <code>exclusive_hulu,</code> because the red line is on the edge of the graph, it likely means that the p-value is very small; similarly to what was previously mentioned, this thus indicates that the observed difference is unlikely to be due to chance if the null hypothesis were true. Hence, this suggests strong evidence against the null hypothesis in favor of the alternate hypothesis.</p>
<p><strong>Extra Note:</strong></p>
<p>We recognize that, in interpreting our results, a post-hoc analysis might’ve been beneficial to use in addition to an ANOVA test to more accurately draw conclusions from our data. In that case, the ANOVA (Analysis of Variance), would be used to test whether there are statistically significant differences between the means of two or more groups (i.e.&nbsp;between <code>exclusive_disney_plus,</code> <code>exclusive_prime_video</code>, <code>exclusive_hulu</code>, and the <code>exclusive_netflix</code>). If a significant difference is found, a post-hoc test like Tukey’s HSD (Honestly Significant Difference) would be utilized to determine which groups in particular are significantly different from each other. However, due to the fact that this was not included in the scope of this course, we decided to omit these tests and instead only perform our traditional hypothesis tests, as seen above.</p>
<p><strong>Conclusions</strong> In the context of our overall analysis of the streaming wars between the most popular streaming platforms in our current pop culture, our hypothesis testing indicates that there</p>
</section>
<section id="limitations" class="level1">
<h1>Limitations</h1>
<p>The first limitation is that our study right now just focuses on the quality of exclusive shows based on their rating scores (Rotten Tomatoes), which may not be a comprehensive measure of the quality of exclusive shows or non-exclusive shows on each platform. The analysis’s focus on Rotten Tomatoes ratings alone may not fully capture the perceived quality of exclusive shows on each platform. Moreover, considering the ratings of exclusive shows and not non-exclusive shows could limit the overall understanding of the quality of each platform’s content.</p>
<p>The second limitation is that we could not find any reliable and consistent dataset for the popularity, preferences, viewerships, viewing rates, or the number of subscribers of each platform, which could also affect the audiences’ perceived quality and critical reception, limiting our study to find the relationship between the quality of exclusive shows or non-exclusive shows and the preference of platforms. This is a result of the competitiveness in the streaming industry. Companies’ revenue almost entirely depends on subscriptions, and some of them are less active in publishing them. Additionally, some of the viewership data we find are using different metrics and, therefore, cannot be used to generate inferences. We can try to find a more comprehensive dataset that includes more variables which we could include in our analysis to reduce bias of confounding variables in hypothesis testing. We could also join dataset with those information.</p>
<p>The third limitation of our study is that there are unbalanced amounts of exclusive shows on each platform; for example, Netflix has significantly larger data of exclusive shows compared to the other platforms, which may affect the overall quality comparison between platforms. Disney Plus is a relatively new platform and has a smaller library of exclusive shows, which may limit the analysis. These unbalanced amounts of exclusive shows on each platform may introduce bias and affect the conclusions we can draw from our analyses.</p>
<p>The fourth limitation is that our analysis plan uses tomato scores to represent quality. This definition could have some biases. Firstly, the tomato score is a critics rating rather than an audience rating. Many movies and shows have a target audience that is better or worse represented than the other. Critics might inadvertently bring bias into their rating, and subsequently, our definition of quality could be biased as well. In addition, some shows that are watched by fewer people are less rated with tomato score, making the score easily influenced by a few critics, and therefore create bias in the definition of quality.</p>
<p>The fifth limitation is that our analysis does not account for the different types or genres of exclusive shows on each platform, such as comedies, documentaries, actions, etc., which may have different average ratings. We would have better insights if we had more data about the genres to compare shows of similar types across platforms rather than just looking at the overall average ratings.</p>
<p>The sixth limitation is that we do not take into account the number of views of each show across all platforms. This is a crucial factor in determining the quality of both exclusive and non-exclusive shows, as it can be a game-changer along with ratings. Many viewers may not rate a show after watching it, so the number of views plays an important role in determining if a show is popular or not, which affects its quality since quality is not solely determined by ratings.<br>
<br>
The seventh limitation is that our data does not include the cost of subscription for each platform. For example, suppose a particular platform has a higher subscription cost. In that case, viewers may have higher expectations for the quality of the content they are paying for and may be more likely to rate shows negatively if they feel they are not getting their money’s worth. Alternatively, if a platform has a lower subscription cost, viewers may be more forgiving of lower-quality content or may rate shows more positively if they feel they are getting a good deal. Additionally, subscription costs can also impact the target audience of a particular platform, as viewers with different budgets may be more likely to subscribe to platforms with lower costs. Overall, it’s important to consider the cost of subscriptions when analyzing the quality of shows across different platforms.</p>
<p>Moreover, there are some other possible variables to consider in the study. The first one is release dates. Media critics have varied opinion on whether the movie/show release year has an relationship with quality or scores of a show. Setting this aside, another way the release date could impact our study is that eariler realsed shows could have a lower possibility of being exclusive, because media exclusiveness isn’t prevalent before Netflix decided to produce its own shows. Therefore, the release year could have an impact on both the exclusiveness and their quality. Similarly, the production budget for each show could be confounding as well, because exclusive shows typically require more budget to produce than non-exclusive shows. Shows with more budget could also provide a better visual experience/hire better actors and thus have an impact on tomato scores. We tried to account these factors but each platforms have a different policy of releasing their data and many of the data aren’t typically released to outside the companies.</p>
</section>
<section id="acknowledgments" class="level1">
<h1>Acknowledgments</h1>
<p>Thanks to this user who published the dataset we are using on Kraggle:</p>
<p><a href="https://www.kaggle.com/datasets/ruchi798/tv-shows-on-netflix-prime-video-hulu-and-disney" class="uri">https://www.kaggle.com/datasets/ruchi798/tv-shows-on-netflix-prime-video-hulu-and-disney</a></p>
<p><br>
</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>